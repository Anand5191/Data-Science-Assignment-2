{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuwlJNF1G4lb"
      },
      "outputs": [],
      "source": [
        "# Q1\n",
        "\"\"\"\n",
        "Key Differences:\n",
        "Feature\t                                     T - Test\t                                   Z -Test\n",
        "Sample                                   Size\tSmall (n < 30)\t                          Large (n ≥ 30)\n",
        "Population Standard Deviation\t     Unknown (estimated from sample)\t                       Known\n",
        "Distribution                    \tUses t-distribution (heavier tails)       \t    Uses normal distribution\n",
        "Example Scenarios:\n",
        "\n",
        "t-Test Example:\n",
        "A researcher wants to compare the average test scores of two small groups of students (n = 15 in each group) to determine if a new teaching method is effective.\n",
        "Since the sample size is small and the population standard deviation is unknown, a t-test is appropriate.\n",
        "\n",
        "z-Test Example:\n",
        "A manufacturer knows the population standard deviation of product weights and wants to test whether a new machine is producing items with the same mean weight.\n",
        "If the sample size is large (n = 50), and the population standard deviation is known, a z-test would be suitable. \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2\n",
        "\n",
        "\"\"\" Differentiation Between One-Tailed and Two-Tailed Tests :\n",
        "In statistical hypothesis testing, the choice between one-tailed and two-tailed tests is crucial as it influences the interpretation of results, the power of the test,\n",
        "and the overall conclusions drawn from data analysis. Below is a comprehensive differentiation between these two types of tests.\n",
        "\n",
        "One-Tailed Tests :\n",
        "Definition :\n",
        "A one-tailed test is a statistical test that evaluates whether a parameter (such as a mean) is either greater than or less than a specified value, but not both. This means\n",
        "that the critical region for rejecting the null hypothesis is located entirely in one tail of the distribution.\n",
        "\n",
        "Characteristics\n",
        "Directional Hypothesis: The alternative hypothesis specifies a direction (e.g., greater than or less than). For example:\n",
        "Right-tailed test: H1:μ>μ0\n",
        "Left-tailed test: H1:μ<μ0\n",
        "Critical Region: The rejection area lies in only one tail of the distribution.\n",
        "Power: A one-tailed test generally has more power to detect an effect in one specified direction because all of the alpha level (significance level) is allocated to that tail.\n",
        "Sample Size: Typically requires a smaller sample size compared to two-tailed tests for achieving similar power levels.\n",
        "Applications :\n",
        "One-tailed tests are often used when researchers have a strong theoretical basis or prior evidence suggesting that an effect can only occur in one direction. Examples include:\n",
        "\n",
        "Testing if a new drug improves recovery rates compared to an existing treatment.\n",
        "Evaluating whether a marketing campaign increases sales beyond a certain threshold.\n",
        "Two-Tailed Tests\n",
        "Definition :\n",
        "A two-tailed test assesses whether a parameter differs from a specified value in either direction. This means that it tests for the possibility of an effect occurring in both directions—greater than or less than.\n",
        "\n",
        "Characteristics :\n",
        "Non-Directional Hypothesis: The alternative hypothesis does not specify a direction. For example:H1:μ≠μ0\n",
        "Critical Region: The rejection areas are split between both tails of the distribution, with half of alpha allocated to each tail.\n",
        "Power: Two-tailed tests generally require larger sample sizes to achieve similar power levels compared to one-tailed tests because they must account for effects in both directions.\n",
        "Conservativeness: They are considered more conservative since they allow for detection of effects regardless of their direction.\n",
        "Applications\n",
        "Two-tailed tests are commonly used when researchers do not have strong prior expectations about the direction of an effect or when it is important to detect effects in both directions. Examples include:\n",
        "\n",
        "Comparing two different medical treatments where either could be superior.\n",
        "Testing changes in website conversion rates without prior knowledge about which change might be better. \"\"\"\n"
      ],
      "metadata": {
        "id": "Fc6PBZJKJLP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3\n",
        "\n",
        "\"\"\" Understanding Type 1 and Type 2 Errors in Hypothesis Testing\n",
        "Hypothesis testing is a fundamental aspect of statistical inference, allowing researchers to make decisions about populations based on sample data. Within this framework,\n",
        " two critical concepts arise: Type 1 errors and Type 2 errors. These errors are essential for understanding the reliability and validity of statistical conclusions.\n",
        "\n",
        "Hypothesis Testing Framework\n",
        "In hypothesis testing, researchers begin by formulating two competing hypotheses:\n",
        "\n",
        "Null Hypothesis (H₀): This hypothesis posits that there is no effect or no difference; it serves as a default position that indicates no change or relationship.\n",
        "Alternative Hypothesis (H₁ or Hₐ): This hypothesis suggests that there is an effect or a difference; it represents what the researcher aims to prove.\n",
        "The goal of hypothesis testing is to determine whether there is sufficient evidence in the sample data to reject the null hypothesis in favor of the alternative hypothesis.\n",
        "\n",
        "Type 1 Error (False Positive)\n",
        "A Type 1 error occurs when the null hypothesis is rejected when it is actually true. This error represents a false positive result, leading researchers to conclude that there is\n",
        "an effect or difference when none exists. The probability of making a Type 1 error is denoted by alpha (α), which is typically set at levels such as 0.05 or 0.01. This means that\n",
        "there is a 5% or 1% chance, respectively, of incorrectly rejecting the null hypothesis.\n",
        "\n",
        "Example Scenario for Type 1 Error\n",
        "Consider a clinical trial testing a new medication intended to lower blood pressure. The null hypothesis (H₀) states that the medication has no effect on blood pressure compared to\n",
        "a placebo. After conducting the trial and analyzing the results, researchers find statistically significant evidence suggesting that the medication does lower blood pressure (p < α).\n",
        "Consequently, they reject H₀ and conclude that the medication works.\n",
        "\n",
        "However, suppose in reality, the medication has no actual effect on blood pressure; thus, they have committed a Type 1 error by falsely concluding its efficacy.\n",
        "\n",
        "Type 2 Error (False Negative)\n",
        "Conversely, a Type 2 error occurs when the null hypothesis is not rejected when it is actually false. This error represents a false negative result, leading researchers to conclude\n",
        "that there is no effect or difference when one truly exists. The probability of making a Type 2 error is denoted by beta (β). The power of a test, which reflects its ability to\n",
        "detect an effect if one exists, can be calculated as (1 - β).\n",
        "\n",
        "Example Scenario for Type 2 Error\n",
        "Continuing with our clinical trial example, let’s say that after analyzing data from another similar study involving different participants but using the same medication and\n",
        "placebo setup, researchers fail to find statistically significant evidence against H₀ (p > α). They conclude that there is insufficient evidence to suggest that the medication\n",
        "lowers blood pressure and thus do not reject H₀.\n",
        "\n",
        "However, if in reality, the medication does indeed lower blood pressure but their study lacked sufficient power due to small sample size or variability in response rates among\n",
        "participants, they have committed a Type 2 error by failing to recognize its effectiveness.\n",
        "\n",
        "Implications of Errors in Research\n",
        "Both types of errors carry significant implications for research findings:\n",
        "\n",
        "Type 1 Errors can lead to unnecessary treatments being approved or implemented based on false claims of effectiveness.\n",
        "Type 2 Errors can prevent beneficial treatments from being recognized and utilized effectively within medical practice or other fields.\n",
        "Researchers must carefully consider their significance levels and ensure adequate sample sizes to minimize these errors while balancing risks associated with both types.\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "azuMkLZjJLW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4\n",
        "\n",
        "\"\"\"Bayes’s Theorem : Bayes’s theorem is a fundamental concept in probability theory and statistics that describes how to update the probability of a hypothesis based on new\n",
        "evidence. Named after the Reverend Thomas Bayes, this theorem provides a mathematical framework for reasoning about uncertainty and making decisions in the presence of incomplete\n",
        "information. It is widely used across various fields, including statistics, finance, medicine, and machine learning.\"\"\""
      ],
      "metadata": {
        "id": "BKnvIH8QK2yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bayes_theorem(P_D, P_T_given_D, P_T_given_not_D):\n",
        "    P_not_D = 1 - P_D\n",
        "    P_T = (P_T_given_D * P_D) + (P_T_given_not_D * P_not_D)\n",
        "\n",
        "    P_D_given_T = (P_T_given_D * P_D) / P_T\n",
        "    return P_D_given_T\n",
        "\n",
        "P_D = 0.001\n",
        "P_T_given_D = 0.9\n",
        "P_T_given_not_D = 0.05\n",
        "\n",
        "result = bayes_theorem(P_D, P_T_given_D, P_T_given_not_D)\n",
        "print(f\"Probability of actually having the disease given a positive test: {result:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26tkx-plK3HD",
        "outputId": "9ae26c0d-177c-4a9f-f400-a979056527f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of actually having the disease given a positive test: 0.0177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5\n",
        "\n",
        "\"\"\" A confidence interval (CI) is a statistical tool used to estimate the range within which a population parameter, such as a mean or proportion, is likely to fall, based on\n",
        "sample data. It provides an interval estimate rather than a point estimate, thereby reflecting the uncertainty inherent in sampling. The concept of confidence intervals is\n",
        "fundamental in inferential statistics, allowing researchers to make probabilistic statements about population parameters based on sample statistics.\"\"\""
      ],
      "metadata": {
        "id": "qHlETc0VK3Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "def confidence_interval(mean, std_dev, n, confidence=0.95):\n",
        "    z_score = stats.norm.ppf(1 - (1 - confidence) / 2)\n",
        "    margin_error = z_score * (std_dev / np.sqrt(n))\n",
        "    return (mean - margin_error, mean + margin_error)\n",
        "\n",
        "mean = 170\n",
        "std_dev = 10\n",
        "n = 100\n",
        "confidence = 0.95\n",
        "\n",
        "ci_lower, ci_upper = confidence_interval(mean, std_dev, n, confidence)\n",
        "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmRpCAKWK3a4",
        "outputId": "5da2f3d7-7d47-4bfa-a165-56d12f742863"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% Confidence Interval: (168.04, 171.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6\n",
        "\n",
        "def bayes_theorem(P_A, P_B_given_A, P_B_given_not_A):\n",
        "    P_not_A = 1 - P_A\n",
        "    P_B = (P_B_given_A * P_A) + (P_B_given_not_A * P_not_A)\n",
        "\n",
        "    P_A_given_B = (P_B_given_A * P_A) / P_B\n",
        "    return P_A_given_B\n",
        "\n",
        "P_Spam = 0.2\n",
        "P_Offer_given_Spam = 0.7\n",
        "P_Offer_given_Not_Spam = 0.1\n",
        "\n",
        "P_Spam_given_Offer = bayes_theorem(P_Spam, P_Offer_given_Spam, P_Offer_given_Not_Spam)\n",
        "print(f\"Probability that an email is spam given it contains 'offer': {P_Spam_given_Offer:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6Wo9FQWMRcJ",
        "outputId": "19e6e5d9-462f-4876-d020-3516654b731f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability that an email is spam given it contains 'offer': 0.6364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7\n",
        "\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "def confidence_interval(mean, std_dev, n, confidence=0.95):\n",
        "    z_score = stats.norm.ppf(1 - (1 - confidence) / 2)\n",
        "    margin_error = z_score * (std_dev / np.sqrt(n))\n",
        "    return (mean - margin_error, mean + margin_error)\n",
        "\n",
        "mean = 50\n",
        "std_dev = 5\n",
        "n = 30\n",
        "\n",
        "ci_lower, ci_upper = confidence_interval(mean, std_dev, n)\n",
        "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwCChiTEMuFk",
        "outputId": "69a57eee-d817-4b9f-d587-ee798169cf8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% Confidence Interval: (48.21, 51.79)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def margin_of_error(std_dev, n, confidence=0.95):\n",
        "    z_score = stats.norm.ppf(1 - (1 - confidence) / 2)\n",
        "    return z_score * (std_dev / np.sqrt(n))\n",
        "\n",
        "std_dev = 1.5\n",
        "confidence = 0.95\n",
        "\n",
        "sample_sizes = [25, 50, 100, 200]\n",
        "for n in sample_sizes:\n",
        "    me = margin_of_error(std_dev, n, confidence)\n",
        "    print(f\"Sample size: {n}, Margin of Error: {me:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuGmwXv_M-le",
        "outputId": "ba016dc1-4d91-40cc-c5cc-c7f6a8c87392"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample size: 25, Margin of Error: 0.588\n",
            "Sample size: 50, Margin of Error: 0.416\n",
            "Sample size: 100, Margin of Error: 0.294\n",
            "Sample size: 200, Margin of Error: 0.208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9\n",
        "\n",
        "def calculate_z_score(X, mean, std_dev):\n",
        "    return (X - mean) / std_dev\n",
        "\n",
        "X = 75\n",
        "mean = 70\n",
        "std_dev = 5\n",
        "\n",
        "z_score = calculate_z_score(X, mean, std_dev)\n",
        "print(f\"Z-score: {z_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1eTr7VbNTY0",
        "outputId": "1feacf75-4ed2-42c0-e3a6-426fcbf665fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q10\n",
        "\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "sample_mean = 6\n",
        "pop_mean = 0\n",
        "std_dev = 2.5\n",
        "n = 50\n",
        "\n",
        "t_stat = (sample_mean - pop_mean) / (std_dev / np.sqrt(n))\n",
        "\n",
        "alpha = 0.05\n",
        "df = n - 1\n",
        "t_critical = stats.t.ppf(1 - alpha, df)\n",
        "\n",
        "print(f\"t-Statistic: {t_stat:.2f}\")\n",
        "print(f\"Critical t-Value: {t_critical:.3f}\")\n",
        "\n",
        "if t_stat > t_critical:\n",
        "    print(\"Reject the null hypothesis: The drug is significantly effective.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant effect detected.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl_CUZbONgx4",
        "outputId": "f2d5f133-84bd-4171-c299-d85448b98806"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t-Statistic: 16.97\n",
            "Critical t-Value: 1.677\n",
            "Reject the null hypothesis: The drug is significantly effective.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q11\n",
        "\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "n = 500\n",
        "p_hat = 0.65\n",
        "z_score = stats.norm.ppf(0.975)\n",
        "\n",
        "margin_error = z_score * np.sqrt((p_hat * (1 - p_hat)) / n)\n",
        "\n",
        "lower_bound = p_hat - margin_error\n",
        "upper_bound = p_hat + margin_error\n",
        "\n",
        "# Print results\n",
        "print(f\"95% Confidence Interval: ({lower_bound:.4f}, {upper_bound:.4f})\")\n",
        "print(f\"95% Confidence Interval as Percentage: ({lower_bound*100:.2f}%, {upper_bound*100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg33RWJlODgH",
        "outputId": "807c5b26-bd89-49b0-8e62-57463ca7368a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% Confidence Interval: (0.6082, 0.6918)\n",
            "95% Confidence Interval as Percentage: (60.82%, 69.18%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q12\n",
        "\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "mean_A = 85\n",
        "std_A = 6\n",
        "n_A = 30\n",
        "\n",
        "mean_B = 82\n",
        "std_B = 5\n",
        "n_B = 30\n",
        "\n",
        "t_stat, p_value = stats.ttest_ind_from_stats(mean_A, std_A, n_A, mean_B, std_B, n_B, equal_var=False)\n",
        "\n",
        "alpha = 0.01\n",
        "df = n_A + n_B - 2\n",
        "t_critical = stats.t.ppf(1 - alpha/2, df)\n",
        "\n",
        "print(f\"t-Statistic: {t_stat:.2f}\")\n",
        "print(f\"Critical t-Value: {t_critical:.3f}\")\n",
        "print(f\"p-Value: {p_value:.4f}\")\n",
        "\n",
        "if abs(t_stat) > t_critical:\n",
        "    print(\"Reject the null hypothesis: Significant difference in teaching methods.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference detected.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA3smIfqOS7i",
        "outputId": "fa0af855-44a3-4ce5-8770-02e911607b4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t-Statistic: 2.10\n",
            "Critical t-Value: 2.663\n",
            "p-Value: 0.0399\n",
            "Fail to reject the null hypothesis: No significant difference detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q13\n",
        "\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "sample_mean = 65\n",
        "pop_std = 8\n",
        "n = 50\n",
        "z_score = stats.norm.ppf(0.95)\n",
        "\n",
        "margin_error = z_score * (pop_std / np.sqrt(n))\n",
        "\n",
        "lower_bound = sample_mean - margin_error\n",
        "upper_bound = sample_mean + margin_error\n",
        "\n",
        "print(f\"90% Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg2VxvWnOkxb",
        "outputId": "4dea1fb9-5181-4b53-814d-d7fabfce7cd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90% Confidence Interval: (63.14, 66.86)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q14\n",
        "\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "sample_mean = 0.25\n",
        "pop_mean = 0.30\n",
        "std_dev = 0.05\n",
        "n = 30\n",
        "\n",
        "t_stat = (sample_mean - pop_mean) / (std_dev / np.sqrt(n))\n",
        "\n",
        "alpha = 0.10\n",
        "df = n - 1\n",
        "t_critical = stats.t.ppf(alpha, df)\n",
        "\n",
        "print(f\"t-Statistic: {t_stat:.2f}\")\n",
        "print(f\"Critical t-Value: {t_critical:.3f}\")\n",
        "\n",
        "if t_stat < t_critical:\n",
        "    print(\"Reject the null hypothesis: Caffeine significantly reduces reaction time.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant effect detected.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5909EXaQO06v",
        "outputId": "0d022b75-fc9b-4656-f8b1-d7993d5b8ce4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t-Statistic: -5.48\n",
            "Critical t-Value: -1.311\n",
            "Reject the null hypothesis: Caffeine significantly reduces reaction time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pA1boH58PE6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}